{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-abcd46e578d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0md_pix_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpix_code_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpix_fake_pred\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mpix_real_pred\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mgp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m         \u001b[0md_pix_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0mopt_dp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.backends import cudnn\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable, grad\n",
    "\n",
    "from src.data import LoadDataset\n",
    "from src.ufdn import LoadModel\n",
    "\n",
    "from src.util import vae_loss, calc_gradient_penalty, interpolate_vae_3d\n",
    "\n",
    "from tensorboardX import SummaryWriter \n",
    "\n",
    "\n",
    "# Experiment Setting\n",
    "cudnn.benchmark = True\n",
    "config_path = 'config/tcga.yaml'\n",
    "conf = yaml.load(open(config_path,'r'))\n",
    "exp_name = conf['exp_setting']['exp_name']\n",
    "img_size = conf['exp_setting']['img_size']\n",
    "img_depth = conf['exp_setting']['img_depth']\n",
    "\n",
    "trainer_conf = conf['trainer']\n",
    "\n",
    "if trainer_conf['save_checkpoint']:\n",
    "    model_path = conf['exp_setting']['checkpoint_dir'] + exp_name+'/'\n",
    "    if not os.path.exists(model_path):\n",
    "        os.makedirs(model_path)\n",
    "    model_path = model_path+'{}'\n",
    "\n",
    "if trainer_conf['save_log'] or trainer_conf['save_fig']:\n",
    "    if os.path.exists(conf['exp_setting']['log_dir']+exp_name):\n",
    "        shutil.rmtree(conf['exp_setting']['log_dir']+exp_name)\n",
    "    writer = SummaryWriter(conf['exp_setting']['log_dir']+exp_name)\n",
    "\n",
    "\n",
    "# Fix seed\n",
    "np.random.seed(conf['exp_setting']['seed'])\n",
    "_ = torch.manual_seed(conf['exp_setting']['seed'])\n",
    "\n",
    "# Load dataset\n",
    "domain_a = conf['exp_setting']['domain_a']\n",
    "doamin_b = conf['exp_setting']['doamin_b']\n",
    "doamin_c = conf['exp_setting']['doamin_c']\n",
    "\n",
    "\n",
    "data_root = conf['exp_setting']['data_root']\n",
    "batch_size = conf['trainer']['batch_size']\n",
    "\n",
    "a_loader = LoadDataset('tcga',data_root,batch_size,'train',style=domain_a)\n",
    "b_loader = LoadDataset('tcga',data_root,batch_size,'train',style=doamin_b)\n",
    "c_loader = LoadDataset('tcga',data_root,batch_size,'train',style=doamin_c)\n",
    "\n",
    "a_test = LoadDataset('tcga',data_root,batch_size,'test',style=domain_a)\n",
    "b_test = LoadDataset('tcga',data_root,batch_size,'test',style=doamin_b)\n",
    "c_test = LoadDataset('tcga',data_root,batch_size,'test',style=doamin_c)\n",
    "\n",
    "\n",
    "for d1,d2,d3 in zip(a_test,b_test,c_test):\n",
    "    #a_test_sample = d1[9].type(torch.FloatTensor) # No idea what this does\n",
    "    a_test_sample = d1[4].type(torch.FloatTensor) # This could be wrong\n",
    "    b_test_sample = d2[0].clone().repeat(3,1,1).type(torch.FloatTensor)\n",
    "    c_test_sample = d3[0].type(torch.FloatTensor)\n",
    "    break\n",
    "\n",
    "\n",
    "\n",
    "# Load Model\n",
    "enc_dim = conf['model']['vae']['encoder'][-1][1]\n",
    "code_dim = conf['model']['vae']['code_dim']\n",
    "vae_learning_rate = conf['model']['vae']['lr']\n",
    "vae_betas = tuple(conf['model']['vae']['betas'])\n",
    "df_learning_rate = conf['model']['D_feat']['lr']\n",
    "df_betas = tuple(conf['model']['D_feat']['betas'])\n",
    "dp_learning_rate = conf['model']['D_pix']['lr']\n",
    "dp_betas = tuple(conf['model']['D_pix']['betas'])\n",
    "\n",
    "vae = LoadModel('vae',conf['model']['vae'],img_size,img_depth) #img_size=64, img_depth = 3. Last arg is input dimension\n",
    "d_feat = LoadModel('nn',conf['model']['D_feat'],img_size,enc_dim) #img_size=64, enc_dim=1024\n",
    "d_pix = LoadModel('nn',conf['model']['D_pix'],img_size,img_depth) #img_size=64, img_depth = 3\n",
    "\n",
    "reconstruct_loss = torch.nn.MSELoss()\n",
    "clf_loss = nn.BCEWithLogitsLoss()\n",
    "\n",
    "\n",
    "# Use cuda\n",
    "#vae = vae.cuda()\n",
    "#d_feat = d_feat.cuda()\n",
    "#d_pix = d_pix.cuda()\n",
    "\n",
    "reconstruct_loss = reconstruct_loss.cuda()\n",
    "clf_loss = clf_loss.cuda()\n",
    "\n",
    "\n",
    "# Optmizer\n",
    "opt_vae = optim.Adam(list(vae.parameters()), lr=vae_learning_rate, betas=vae_betas)\n",
    "opt_df = optim.Adam(list(d_feat.parameters()), lr=df_learning_rate, betas=df_betas)\n",
    "opt_dp = optim.Adam(list(d_pix.parameters()), lr=dp_learning_rate, betas=dp_betas)\n",
    "\n",
    "# Training\n",
    "\n",
    "vae.train()\n",
    "d_feat.train()\n",
    "d_pix.train()\n",
    "\n",
    "    \n",
    "# Domain code setting\n",
    "domain_code = np.concatenate([np.repeat(np.array([[*([1]*int(code_dim/3)),\n",
    "                                                   *([0]*int(code_dim/3)),\n",
    "                                                   *([0]*int(code_dim/3))]]),batch_size,axis=0),\n",
    "                              np.repeat(np.array([[*([0]*int(code_dim/3)),\n",
    "                                                   *([1]*int(code_dim/3)),\n",
    "                                                   *([0]*int(code_dim/3))]]),batch_size,axis=0),\n",
    "                              np.repeat(np.array([[*([0]*int(code_dim/3)),\n",
    "                                                   *([0]*int(code_dim/3)),\n",
    "                                                   *([1]*int(code_dim/3))]]),batch_size,axis=0)],\n",
    "                              axis=0)\n",
    "\n",
    "domain_code = torch.FloatTensor(domain_code)\n",
    "\n",
    "### Messy, torch.randperm will be better approach\n",
    "# forword translation code : A->B->C->A\n",
    "forword_code = np.concatenate([np.repeat(np.array([[*([0]*int(code_dim/3)),\n",
    "                                                   *([1]*int(code_dim/3)),\n",
    "                                                   *([0]*int(code_dim/3))]]),batch_size,axis=0),\n",
    "                              np.repeat(np.array([[*([0]*int(code_dim/3)),\n",
    "                                                   *([0]*int(code_dim/3)),\n",
    "                                                   *([1]*int(code_dim/3))]]),batch_size,axis=0),\n",
    "                              np.repeat(np.array([[*([1]*int(code_dim/3)),\n",
    "                                                   *([0]*int(code_dim/3)),\n",
    "                                                   *([0]*int(code_dim/3))]]),batch_size,axis=0)],\n",
    "                              axis=0)\n",
    "\n",
    "forword_code = torch.FloatTensor(forword_code)\n",
    "\n",
    "# backword translation code : C->B->A->C\n",
    "backword_code = np.concatenate([np.repeat(np.array([[*([0]*int(code_dim/3)),\n",
    "                                                   *([0]*int(code_dim/3)),\n",
    "                                                   *([1]*int(code_dim/3))]]),batch_size,axis=0),\n",
    "                              np.repeat(np.array([[*([1]*int(code_dim/3)),\n",
    "                                                   *([0]*int(code_dim/3)),\n",
    "                                                   *([0]*int(code_dim/3))]]),batch_size,axis=0),\n",
    "                              np.repeat(np.array([[*([0]*int(code_dim/3)),\n",
    "                                                   *([1]*int(code_dim/3)),\n",
    "                                                   *([0]*int(code_dim/3))]]),batch_size,axis=0)],\n",
    "                              axis=0)\n",
    "\n",
    "backword_code = torch.FloatTensor(backword_code)\n",
    "\n",
    "\n",
    "\n",
    "# Loss weight setting\n",
    "loss_lambda = {}\n",
    "for k in trainer_conf['lambda'].keys():\n",
    "    init = trainer_conf['lambda'][k]['init']\n",
    "    final = trainer_conf['lambda'][k]['final']\n",
    "    step = trainer_conf['lambda'][k]['step']\n",
    "    loss_lambda[k] = {}\n",
    "    loss_lambda[k]['cur'] = init\n",
    "    loss_lambda[k]['inc'] = (final-init)/step\n",
    "    loss_lambda[k]['final'] = final\n",
    "\n",
    "\n",
    "\n",
    "# Training \n",
    "global_step = 0\n",
    "\n",
    "\n",
    "while global_step < trainer_conf['total_step']:\n",
    "    \n",
    "    for a_img,b_img,c_img in zip(a_loader,b_loader,c_loader):\n",
    "        \n",
    "        # data augmentation\n",
    "        input_img = torch.cat([a_img.type(torch.FloatTensor),\n",
    "                               #b_img.clone().repeat(1,3,1,1).type(torch.FloatTensor), # No idea what this is doing\n",
    "                               b_img.type(torch.FloatTensor),\n",
    "                               c_img.type(torch.FloatTensor)],dim=0)\n",
    "        #input_img =  Variable(input_img.cuda(),requires_grad=False)\n",
    "        input_img =  Variable(input_img,requires_grad=False)\n",
    "\n",
    "\n",
    "        #code = Variable(torch.FloatTensor(domain_code).cuda(),requires_grad=False)\n",
    "        code = Variable(torch.FloatTensor(domain_code),requires_grad=False)\n",
    "        \n",
    "        invert_code = 1-code\n",
    "\n",
    "        if global_step%2 == 0:\n",
    "            #trans_code = Variable(torch.FloatTensor(forword_code).cuda(),requires_grad=False)\n",
    "            trans_code = Variable(torch.FloatTensor(forword_code),requires_grad=False)\n",
    "        else:\n",
    "            #trans_code = Variable(torch.FloatTensor(backword_code).cuda(),requires_grad=False)\n",
    "            trans_code = Variable(torch.FloatTensor(backword_code),requires_grad=False)\n",
    "      \n",
    "        # Train Feature Discriminator\n",
    "        opt_df.zero_grad()\n",
    "        \n",
    "        enc_x = vae(input_img,return_enc=True).detach()\n",
    "        code_pred = d_feat(enc_x)\n",
    "\n",
    "        df_loss = clf_loss(code_pred,code)\n",
    "        df_loss.backward()\n",
    "     \n",
    "        opt_df.step()\n",
    "        \n",
    "        # Train Pixel Discriminator\n",
    "        opt_dp.zero_grad()\n",
    "        \n",
    "        pix_real_pred,pix_real_code_pred = d_pix(input_img)\n",
    "        \n",
    "        fake_img = vae(input_img,insert_attrs=trans_code)[0].detach()\n",
    "        pix_fake_pred, _  = d_pix(fake_img)\n",
    "        \n",
    "        pix_real_pred = pix_real_pred.mean()\n",
    "        pix_fake_pred = pix_fake_pred.mean()\n",
    "\n",
    "        gp = loss_lambda['gp']['cur']*calc_gradient_penalty(d_pix,input_img.data,fake_img.data,use_gpu = False)\n",
    "        pix_code_loss = clf_loss(pix_real_code_pred,code)\n",
    "        \n",
    "        d_pix_loss = pix_code_loss + pix_fake_pred - pix_real_pred + gp\n",
    "        d_pix_loss.backward()\n",
    "        \n",
    "        opt_dp.step()\n",
    "        \n",
    "        # Train VAE\n",
    "        opt_vae.zero_grad()\n",
    "        \n",
    "        ### Reconstruction Phase\n",
    "        recon_batch, mu, logvar = vae(input_img,insert_attrs = code)\n",
    "        mse,kl = vae_loss(recon_batch, input_img, mu, logvar, reconstruct_loss)  #.view(batch_size,-1)\n",
    "        recon_loss = (loss_lambda['pix_recon']['cur']*mse+loss_lambda['kl']['cur']*kl)\n",
    "        recon_loss.backward()\n",
    "\n",
    "        \n",
    "        ### Feature space adversarial Phase       \n",
    "        enc_x = vae(input_img,return_enc=True)\n",
    "        domain_pred = d_feat(enc_x)\n",
    "        adv_code_loss = clf_loss(domain_pred,invert_code)\n",
    "        \n",
    "        feature_loss = loss_lambda['feat_domain']['cur']*adv_code_loss\n",
    "        feature_loss.backward()\n",
    "        \n",
    "        ### Pixel space adversarial Phase\n",
    "        enc_x = vae(input_img,return_enc=True).detach()\n",
    "        \n",
    "        fake_img = vae.decode(enc_x,trans_code)\n",
    "        recon_enc_x = vae(fake_img,return_enc=True)\n",
    "        adv_pix_loss, pix_code_pred = d_pix(fake_img)\n",
    "        adv_pix_loss = adv_pix_loss.mean()\n",
    "        pix_clf_loss = clf_loss(pix_code_pred,trans_code)\n",
    "        \n",
    "        \n",
    "        pixel_loss =  - loss_lambda['pix_adv']['cur']*adv_pix_loss + loss_lambda['pix_clf']['cur']*pix_clf_loss\n",
    "        pixel_loss.backward()\n",
    "        \n",
    "        opt_vae.step()\n",
    "        \n",
    "        \n",
    "        # End of step      \n",
    "        print('Step',global_step,end='\\r',flush=True)     \n",
    "        global_step += 1\n",
    "        \n",
    "        # Records\n",
    "        if trainer_conf['save_log'] and (global_step % trainer_conf['verbose_step'] ==0):\n",
    "            writer.add_scalar('MSE', mse.data[0], global_step)\n",
    "            writer.add_scalar('KL',  kl.data[0], global_step)\n",
    "            writer.add_scalar('gp', gp.data[0], global_step)\n",
    "            writer.add_scalars('Pixel_Distance',{'real':pix_real_pred.data[0],\n",
    "                                               'fake':pix_fake_pred.data[0]}, global_step)\n",
    "            writer.add_scalars('Code_loss',{'feature':df_loss.data[0],\n",
    "                                            'pixel':pix_code_loss.data[0],\n",
    "                                           'adv_feature':feature_loss.data[0],\n",
    "                                           'adv_pixel':pix_clf_loss.data[0]}, global_step)\n",
    "\n",
    "            \n",
    "        # update lambda\n",
    "        for k in loss_lambda.keys():\n",
    "            if loss_lambda[k]['inc']*loss_lambda[k]['cur'] < loss_lambda[k]['inc']*loss_lambda[k]['final']:\n",
    "                loss_lambda[k]['cur'] += loss_lambda[k]['inc']\n",
    "                \n",
    "\n",
    "\n",
    "        if global_step%trainer_conf['checkpoint_step']==0 and trainer_conf['save_checkpoint'] and not trainer_conf['save_best_only']:\n",
    "            torch.save(vae,model_path.format(global_step)+'.vae')\n",
    "\n",
    "\n",
    "        ### Show result\n",
    "        '''\n",
    "        if global_step% trainer_conf['plot_step'] ==0:\n",
    "            vae.eval()\n",
    "            \n",
    "            # Reconstruct\n",
    "            tmp = interpolate_vae_3d(vae,a_test_sample,b_test_sample,c_test_sample,attr_max=1.0,attr_dim=code_dim)\n",
    "            fig1 = (tmp+1)/2\n",
    "\n",
    "            \n",
    "            # Generate\n",
    "            tmp = interpolate_vae_3d(vae,a_test_sample,b_test_sample,c_test_sample,attr_max=1.0,random_test=True,\n",
    "                                  sd =conf['exp_setting']['seed'],attr_dim=code_dim)\n",
    "            fig2 = (tmp+1)/2\n",
    "            \n",
    "            if trainer_conf['save_fig']:\n",
    "                writer.add_image('interpolate', torch.FloatTensor(np.transpose(fig1,(2,0,1))), global_step)\n",
    "                writer.add_image('random generate', torch.FloatTensor(np.transpose(fig2,(2,0,1))), global_step)\n",
    "\n",
    "            vae.train()\n",
    "        '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
